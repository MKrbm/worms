{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(epoch : int) -> float:\n",
    "    lr = 1\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    elif epoch < 10:\n",
    "        return 0.8 * lr\n",
    "    elif epoch < 15:\n",
    "        return 0.5 * lr\n",
    "    elif epoch < 20:\n",
    "        return 0.1 * lr\n",
    "    elif epoch < 30:\n",
    "        return 0.07 * lr\n",
    "    elif epoch < 80:\n",
    "        return 0.05 * lr\n",
    "    else:\n",
    "        return 0.01 * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.5       , 0.33333333, 0.25      , 0.2       ,\n",
       "       0.16666667, 0.14285714, 0.125     , 0.11111111, 0.1       ,\n",
       "       0.09090909, 0.08333333, 0.07692308, 0.07142857, 0.06666667,\n",
       "       0.0625    , 0.05882353, 0.05555556, 0.05263158, 0.05      ,\n",
       "       0.04761905, 0.04545455, 0.04347826, 0.04166667, 0.04      ,\n",
       "       0.03846154, 0.03703704, 0.03571429, 0.03448276, 0.03333333,\n",
       "       0.03225806, 0.03125   , 0.03030303, 0.02941176, 0.02857143,\n",
       "       0.02777778, 0.02702703, 0.02631579, 0.02564103, 0.025     ,\n",
       "       0.02439024, 0.02380952, 0.02325581, 0.02272727, 0.02222222,\n",
       "       0.02173913, 0.0212766 , 0.02083333, 0.02040816, 0.02      ,\n",
       "       0.01960784, 0.01923077, 0.01886792, 0.01851852, 0.01818182,\n",
       "       0.01785714, 0.01754386, 0.01724138, 0.01694915, 0.01666667,\n",
       "       0.01639344, 0.01612903, 0.01587302, 0.015625  , 0.01538462,\n",
       "       0.01515152, 0.01492537, 0.01470588, 0.01449275, 0.01428571,\n",
       "       0.01408451, 0.01388889, 0.01369863, 0.01351351, 0.01333333,\n",
       "       0.01315789, 0.01298701, 0.01282051, 0.01265823, 0.0125    ,\n",
       "       0.01234568, 0.01219512, 0.01204819, 0.01190476, 0.01176471,\n",
       "       0.01162791, 0.01149425, 0.01136364, 0.01123596, 0.01111111,\n",
       "       0.01098901, 0.01086957, 0.01075269, 0.0106383 , 0.01052632,\n",
       "       0.01041667, 0.01030928, 0.01020408, 0.01010101, 0.01      ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5d819992b0>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0, 100, 1)\n",
    "y = [lr_lambda(i) for i in x]\n",
    "\n",
    "#* log scale y axis\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, np.exp(-x/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rms' from '/home/user/project/python/rmsKit/rms/__init__.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rms\n",
    "reload(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitaryRiemanGenerator is initialized\n"
     ]
    }
   ],
   "source": [
    "ur = rms.unitary.UnitaryRiemanGenerator(8, jax.random.PRNGKey(0), np.float64)\n",
    "u = ur.reset_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/user/project/python/rmsKit\")\n",
    "from jax_lattice import KH\n",
    "\n",
    "p = dict(\n",
    "    Jx=1,\n",
    "    Jy=1,\n",
    "    Jz=1,\n",
    "    hx=0,\n",
    "    hz=0,\n",
    ")\n",
    "H = KH.system([2, 2], \"3site\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "u = np.load(\"array/KH/3site/sel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/M_1/u/0.npy\")\n",
    "# U = np.kron(u,u)\n",
    "# U = np.kron(U,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = rms.loss.init_loss(jnp.array(H), 8, np.float64, \"sel\", beta=1.0)\n",
    "state_list = [state]\n",
    "qesLoss = rms.loss.system_el_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(u):\n",
    "    return qesLoss(state_list, jnp.array(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loss(jnp.array(u)).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "v, g = jax.value_and_grad(loss)(jnp.array(u))\n",
    "v.block_until_ready(), g.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"/home/user/project/python/rmsKit\")\n",
    "import os\n",
    "import torch\n",
    "from lattice import KH\n",
    "# # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "# # os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "import rms_torch\n",
    "import numpy as np\n",
    "# u = np.load(\"/home/user/project/python/rmsKit/array/KH/3site/sel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/M_1/u/0.npy\")\n",
    "u = np.load(\"/home/user/project/python/rmsKit/array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/M_1_e_50_lr_0.5/u/0.npy\")\n",
    "device = torch.device(\"cuda\")\n",
    "p = dict(\n",
    "    Jx=1,\n",
    "    Jy=1,\n",
    "    Jz=1,\n",
    "    hx=0,\n",
    "    hz=0,\n",
    ")\n",
    "H = KH.system([2, 2], \"3site\", p)\n",
    "# Create an instance of the CustomModel class\n",
    "E, V = np.linalg.eigh(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m H_gpu \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(H, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m rms_torch\u001b[39m.\u001b[39mUnitaryRieman(H\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m8\u001b[39m, device\u001b[39m=\u001b[39mdevice, u0\u001b[39m=\u001b[39mu)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m loss \u001b[39m=\u001b[39m rms_torch\u001b[39m.\u001b[39;49mSystemMinimumEnergyLoss(H, device\u001b[39m=\u001b[39;49mdevice)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m compiled_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcompile(model, dynamic \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, fullgraph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m compiled_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcompile(loss, dynamic \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, fullgraph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/project/python/rmsKit/rms_torch/loss.py:68\u001b[0m, in \u001b[0;36mSystemMinimumEnergyLoss.__init__\u001b[0;34m(self, H, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, H: Union[np\u001b[39m.\u001b[39mndarray, torch\u001b[39m.\u001b[39mTensor], device: torch\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39msuper\u001b[39;49m(SystemMinimumEnergyLoss, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(H, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     71\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(H)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "H_gpu = torch.tensor(H, dtype=torch.float64, device=device)\n",
    "model = rms_torch.UnitaryRieman(H.shape[0], 8, device=device, u0=u).to(device)\n",
    "loss = rms_torch.SystemMinimumEnergyLoss(H, device=device).to(device)\n",
    "compiled_model = torch.compile(model, dynamic = False, fullgraph=True)\n",
    "compiled_loss = torch.compile(loss, dynamic = False, fullgraph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4096x4096 and 81x81)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m rms_torch\u001b[39m.\u001b[39mLION(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 4\u001b[0m loss\u001b[39m.\u001b[39;49minitialize(model())\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Zero out the gradients\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/project/python/rmsKit/rms_torch/loss.py:101\u001b[0m, in \u001b[0;36mSystemMinimumEnergyLoss.initialize\u001b[0;34m(self, U)\u001b[0m\n\u001b[1;32m     99\u001b[0m     U \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meye(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    100\u001b[0m U \u001b[39m=\u001b[39m U\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m--> 101\u001b[0m A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(U, torch\u001b[39m.\u001b[39;49mmatmul(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH, U\u001b[39m.\u001b[39;49mT))\n\u001b[1;32m    102\u001b[0m H_tilde \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstoquastic(A)\n\u001b[1;32m    103\u001b[0m E, V \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meigh(H_tilde)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4096x4096 and 81x81)"
     ]
    }
   ],
   "source": [
    "# optimizer = rms_torch.Adam(compiled_model.parameters(), lr=1e-3, amsgrad=True)\n",
    "optimizer = rms_torch.LION(model.parameters(), lr=1*1e-3)\n",
    "num_epochs = 10\n",
    "loss.initialize(model())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model()\n",
    "    _loss = loss(output)\n",
    "    _loss.backward()\n",
    "    for p in model.parameters():\n",
    "        grad = p.grad  # Get the gradient from the compiled model\n",
    "        if grad is not None:\n",
    "            grad.data[:] = rms_torch.riemannian_grad_torch(p.data, grad)\n",
    "        else:\n",
    "            raise RuntimeError(\"No gradient for parameter\")\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_loss.V_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 4096])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(z+2) if True else (z+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.161143\n",
      "../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.197812\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "def list_unitaries(path, n_percent=None, n_top=None, thres=None):\n",
    "    loss_folders = [\n",
    "        entry.path for entry in os.scandir(path) if entry.is_dir() and entry.name.startswith(\"loss_\")\n",
    "    ]\n",
    "\n",
    "    def get_folder_number(folder_name):\n",
    "        match = re.search(r\"loss_(\\d+\\.\\d+)\", folder_name)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return float(\"inf\")\n",
    "\n",
    "    loss_folders.sort(key=get_folder_number)\n",
    "    selected_folders = [loss_folders for _ in range(3)]\n",
    "\n",
    "    if n_percent is not None:\n",
    "        if isinstance(n_percent, int) and 0 <= n_percent <= 100:\n",
    "            num_folders = int(len(loss_folders) * n_percent / 100)\n",
    "            selected_folders[0] = loss_folders[:num_folders]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid n_percent value. Please enter an integer value between 0 and 100.\")\n",
    "\n",
    "    if n_top is not None:\n",
    "        if isinstance(n_top, int) and 0 <= n_top <= len(loss_folders):\n",
    "            selected_folders[1] = loss_folders[:n_top]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid n_top value. Please enter an integer value between 0 and the total number of folders.\")\n",
    "\n",
    "    if thres is not None:\n",
    "        if isinstance(thres, (int, float)):\n",
    "            selected_folders[2] = [folder for folder in loss_folders if get_folder_number(folder) < thres]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid threshold value. Please enter a valid number.\")\n",
    "\n",
    "    # 3つのリストのうち要素数が最も少ないものを選択\n",
    "    result = min(selected_folders, key=len)\n",
    "    return result\n",
    "\n",
    "path = \"../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5\"  # ディレクトリのパスを指定してください\n",
    "loss_folders = list_unitaries(path, n_top=10, thres=8.2)\n",
    "\n",
    "for folder in loss_folders:\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.977042',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.899173',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.791781',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.784688',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.730649',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.598964',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.577018',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.489171',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.450588',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.365743',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.275466',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.271066',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.261912',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.191866',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.189719',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.171665',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.081785',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_9.068416',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.965562',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.958275',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.942443',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.936326',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.934967',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.917678',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.857450',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.835845',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.705478',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.691806',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.671092',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.669106',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.645495',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.606419',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.593450',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.589636',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.573960',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.555533',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.551776',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.550237',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.544872',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.532559',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.531009',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.523286',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.516493',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.512897',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.511711',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.506212',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.504619',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.500255',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.500245',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.498080',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.496029',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.495646',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.495200',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.494950',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.494824',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.493936',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.491135',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.490715',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.490622',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.485745',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.484326',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.483839',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.482978',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.482950',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.481048',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.473473',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.472696',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.472679',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.472517',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.471863',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.471332',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.471291',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.469788',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.468634',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.468550',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.467921',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.467106',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.462990',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.462975',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.461182',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.459181',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.458581',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.458330',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.454806',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.451410',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.449738',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.445944',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.443938',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.443268',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.436657',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.434198',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.434023',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.433774',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.433584',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.433329',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.430870',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.430319',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.430274',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.429146',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.429057',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.428092',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.426351',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.425069',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.424566',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.424042',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.423877',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.423104',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.422047',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.421574',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.416227',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.414898',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.414258',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.412459',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.412290',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.411720',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.411267',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.411097',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.410815',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.410325',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.408557',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.406558',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.403619',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.403249',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.401516',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.401253',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.400760',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.400447',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.399327',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.399034',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.396505',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.395585',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.394932',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.393571',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.392557',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.390075',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.388830',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.388634',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.386624',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.386278',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.384987',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.383543',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.383097',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.382146',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.381595',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.381346',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.375343',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.372863',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.371088',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.370778',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.370717',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.369222',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.368942',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.368857',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.368436',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.366451',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.366055',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.355085',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.353735',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.353367',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.349092',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.341403',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.336170',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.316851',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.314183',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.309431',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.301737',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.297024',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.287461',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.258731',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.257471',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.253946',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.249388',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.236210',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.222577',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.209051',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.206533',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.197812',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_8.161143',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_12.141636',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_11.201482',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_11.129121',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.812261',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.784816',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.747557',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.736427',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.730080',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.659223',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.643863',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.616956',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.566043',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.490894',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.438945',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.367714',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.341086',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.338698',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.286015',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.261287',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.161978',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.109590',\n",
       " '../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5/loss_10.081562']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = list_unitaries(\"../array/torch/KH/3site/sqel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/e_30_lr_0.5\")\n",
    "sorted(li)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 8.004105424341045\n",
      "Epoch: 1, Loss: 8.003236965858935\n",
      "Epoch: 2, Loss: 8.003438837389412\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m     11\u001b[0m output \u001b[39m=\u001b[39m compiled_model()\n\u001b[0;32m---> 12\u001b[0m _loss \u001b[39m=\u001b[39m compiled_loss(output)\n\u001b[1;32m     13\u001b[0m _loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m compiled_model\u001b[39m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:82\u001b[0m, in \u001b[0;36mOptimizedModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdynamo_ctx(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orig_mod\u001b[39m.\u001b[39;49mforward)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    210\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/project/python/rmsKit/rms_torch/loss.py:84\u001b[0m, in \u001b[0;36mSystemMinimumEnergyLoss.forward\u001b[0;34m(self, U)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV_old \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m#* V_tilde\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mE_old \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m#* E_min_tilde\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, U: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     85\u001b[0m     A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(U, torch\u001b[39m.\u001b[39mmatmul(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH, U\u001b[39m.\u001b[39mT))\n\u001b[1;32m     86\u001b[0m     H_tilde \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstoquastic(A)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    210\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:2819\u001b[0m, in \u001b[0;36maot_module_simplified.<locals>.forward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   2817\u001b[0m full_args\u001b[39m.\u001b[39mextend(params_flat)\n\u001b[1;32m   2818\u001b[0m full_args\u001b[39m.\u001b[39mextend(runtime_args)\n\u001b[0;32m-> 2819\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn(full_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1222\u001b[0m, in \u001b[0;36mmake_boxed_func.<locals>.g\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg\u001b[39m(args):\n\u001b[0;32m-> 1222\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:2386\u001b[0m, in \u001b[0;36maot_dispatch_autograd.<locals>.debug_compiled_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2380\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m can_require_grad:\n\u001b[1;32m   2381\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m a\u001b[39m.\u001b[39mrequires_grad, format_guard_bug_msg(\n\u001b[1;32m   2382\u001b[0m             aot_config,\n\u001b[1;32m   2383\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdescribe_input(i, aot_config)\u001b[39m}\u001b[39;00m\u001b[39m would not require grad\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2384\u001b[0m         )\n\u001b[0;32m-> 2386\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_function(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1898\u001b[0m, in \u001b[0;36mcreate_runtime_wrapper.<locals>.runtime_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     args_with_synthetic_bases \u001b[39m=\u001b[39m args\n\u001b[1;32m   1897\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39m_force_original_view_tracking(\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m-> 1898\u001b[0m     all_outs \u001b[39m=\u001b[39m call_func_with_args(\n\u001b[1;32m   1899\u001b[0m         compiled_fn,\n\u001b[1;32m   1900\u001b[0m         args_with_synthetic_bases,\n\u001b[1;32m   1901\u001b[0m         disable_amp\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1902\u001b[0m     )\n\u001b[1;32m   1904\u001b[0m num_mutated_inps \u001b[39m=\u001b[39m runtime_metadata\u001b[39m.\u001b[39mnum_mutated_inputs\n\u001b[1;32m   1905\u001b[0m num_metadata_mutated_inps \u001b[39m=\u001b[39m runtime_metadata\u001b[39m.\u001b[39mnum_mutated_metadata_inputs\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1247\u001b[0m, in \u001b[0;36mcall_func_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m\"\u001b[39m\u001b[39m_boxed_call\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1247\u001b[0m         out \u001b[39m=\u001b[39m normalize_as_list(f(args))\n\u001b[1;32m   1248\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1249\u001b[0m         \u001b[39m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m         \u001b[39m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYour compiler for AOTAutograd is returning a a function that doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt take boxed arguments. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1253\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1222\u001b[0m, in \u001b[0;36mmake_boxed_func.<locals>.g\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg\u001b[39m(args):\n\u001b[0;32m-> 1222\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:2151\u001b[0m, in \u001b[0;36maot_dispatch_autograd.<locals>.CompiledFunction.forward\u001b[0;34m(ctx, *deduped_flat_tensor_args)\u001b[0m\n\u001b[1;32m   2143\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m   2144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, \u001b[39m*\u001b[39mdeduped_flat_tensor_args):\n\u001b[1;32m   2145\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     \u001b[39m# - Note that in the synthetic bases case, mutated_inputs will correspond to an updated version\u001b[39;00m\n\u001b[1;32m   2150\u001b[0m     \u001b[39m#   of the original view, and not the synthetic base\u001b[39;00m\n\u001b[0;32m-> 2151\u001b[0m     fw_outs \u001b[39m=\u001b[39m call_func_with_args(\n\u001b[1;32m   2152\u001b[0m         CompiledFunction\u001b[39m.\u001b[39;49mcompiled_fw,\n\u001b[1;32m   2153\u001b[0m         deduped_flat_tensor_args,\n\u001b[1;32m   2154\u001b[0m         disable_amp\u001b[39m=\u001b[39;49mdisable_amp,\n\u001b[1;32m   2155\u001b[0m     )\n\u001b[1;32m   2157\u001b[0m     num_outputs \u001b[39m=\u001b[39m CompiledFunction\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mnum_outputs\n\u001b[1;32m   2158\u001b[0m     num_outputs_aliased_to_inputs \u001b[39m=\u001b[39m (\n\u001b[1;32m   2159\u001b[0m         CompiledFunction\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mnum_outputs_aliased_to_inputs\n\u001b[1;32m   2160\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1247\u001b[0m, in \u001b[0;36mcall_func_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m\"\u001b[39m\u001b[39m_boxed_call\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1247\u001b[0m         out \u001b[39m=\u001b[39m normalize_as_list(f(args))\n\u001b[1;32m   1248\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1249\u001b[0m         \u001b[39m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m         \u001b[39m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYour compiler for AOTAutograd is returning a a function that doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt take boxed arguments. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1253\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_inductor/compile_fx.py:248\u001b[0m, in \u001b[0;36malign_inputs.<locals>.run\u001b[0;34m(new_inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m new_inputs[i]\u001b[39m.\u001b[39mdata_ptr() \u001b[39m%\u001b[39m ALIGNMENT:\n\u001b[1;32m    247\u001b[0m         new_inputs[i] \u001b[39m=\u001b[39m clone_preserve_strides(new_inputs[i])\n\u001b[0;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m model(new_inputs)\n",
      "File \u001b[0;32m/tmp/torchinductor_user/gf/cgfaxpw2x65almiqczsyfqnoegk24vyuf627ektfpzeclz2lktmi.py:165\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdel\u001b[39;00m primals_6\n\u001b[1;32m    164\u001b[0m \u001b[39mdel\u001b[39;00m primals_8\n\u001b[0;32m--> 165\u001b[0m buf4 \u001b[39m=\u001b[39m aten\u001b[39m.\u001b[39;49m_linalg_solve_ex(buf3, primals_9)\n\u001b[1;32m    166\u001b[0m \u001b[39mdel\u001b[39;00m buf3\n\u001b[1;32m    167\u001b[0m \u001b[39mdel\u001b[39;00m primals_9\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = rms_torch.Adam(compiled_model.parameters(), lr=1e-3, amsgrad=True)\n",
    "optimizer = rms_torch.LION(compiled_model.parameters(), lr=1*1e-3)\n",
    "num_epochs = 10\n",
    "compiled_loss.reset(compiled_model())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = compiled_model()\n",
    "    _loss = compiled_loss(output)\n",
    "    _loss.backward(retain_graph=True)\n",
    "    for p in compiled_model.parameters():\n",
    "        grad = p.grad  # Get the gradient from the compiled model\n",
    "        if grad is not None:\n",
    "            grad.data[:] = rms_torch.riemannian_grad_torch(p.data, grad)\n",
    "        else:\n",
    "            raise RuntimeError(\"No gradient for parameter\")\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.5696e-01,  1.7097e-01,  1.9867e-01, -1.2842e-01, -1.0919e-01,\n",
       "          6.8600e-01, -2.0272e-01, -5.7023e-01],\n",
       "        [-3.8232e-02, -5.4888e-01,  1.9174e-01,  4.7085e-01,  2.6820e-01,\n",
       "          4.8821e-01, -2.3459e-02,  3.5774e-01],\n",
       "        [-3.5027e-01, -3.8501e-01, -1.0177e-01, -1.7628e-01, -3.0537e-01,\n",
       "          3.9967e-02,  7.6094e-01, -1.1732e-01],\n",
       "        [-8.9114e-02, -2.2356e-01, -7.4985e-01, -4.1507e-01,  3.4657e-01,\n",
       "          1.9739e-01, -2.1377e-01,  5.2455e-02],\n",
       "        [ 1.7096e-01, -1.5171e-01,  5.6047e-01, -7.0626e-01,  3.2317e-01,\n",
       "          1.1962e-02,  6.7080e-02,  1.6045e-01],\n",
       "        [-5.7808e-01, -3.9429e-01,  1.8568e-01,  3.4663e-02,  1.0437e-01,\n",
       "         -4.8289e-01, -4.0521e-01, -2.5770e-01],\n",
       "        [ 1.4227e-01, -3.0032e-01, -1.6723e-04, -2.2395e-01, -7.6582e-01,\n",
       "          8.1621e-02, -4.0599e-01,  2.8538e-01],\n",
       "        [-6.4671e-01,  4.5012e-01,  5.0319e-02, -9.1091e-02, -3.1170e-02,\n",
       "          1.0248e-01, -1.0116e-02,  5.9729e-01]], device='cuda:0',\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No gradient for parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m         grad\u001b[39m.\u001b[39mdata[:] \u001b[39m=\u001b[39m rms_torch\u001b[39m.\u001b[39mriemannian_grad_torch(p\u001b[39m.\u001b[39mdata, grad)\n\u001b[1;32m     16\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo gradient for parameter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No gradient for parameter"
     ]
    }
   ],
   "source": [
    "compiled_model.reset_params()\n",
    "optimizer = rms_torch.LION(compiled_model.parameters(), lr=3*1e-4)\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = compiled_model()\n",
    "    loss = compiled_loss(output)\n",
    "    loss.backward()\n",
    "    for p in model.parameters():\n",
    "        grad = p.grad  # Get the gradient from the compiled model\n",
    "        if grad is not None:\n",
    "            grad.data[:] = rms_torch.riemannian_grad_torch(p.data, grad)\n",
    "        else:\n",
    "            raise RuntimeError(\"No gradient for parameter\")\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from importlib import reload\n",
    "import sys\n",
    "sys.path.append(\"/home/user/project/python/rmsKit\")\n",
    "import rms\n",
    "\n",
    "import jax \n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "sys.path.append(\"/home/user/project/python/reduce_nsp\")\n",
    "sys.path.append(\"/home/user/project/python/exact\")\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "groundstate = np.load(\"/home/user/project/python/exact/test/out/KH_2x2/Jx_1_Jy_1_Jz_1_h_0/groundstate.npy\")\n",
    "u = np.load(\"/home/user/project/python/rmsKit/array/KH/3site/sel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/M_1/u/0.npy\")\n",
    "H0 = -np.load(\"/home/user/project/python/rmsKit/array/KH/3site/none/Jx_1_Jy_1_Jz_1_hx_0_hz_0/H/0.npy\")\n",
    "H1 = -np.load(\"/home/user/project/python/rmsKit/array/KH/3site/none/Jx_1_Jy_1_Jz_1_hx_0_hz_0/H/1.npy\")\n",
    "H2 = -np.load(\"/home/user/project/python/rmsKit/array/KH/3site/none/Jx_1_Jy_1_Jz_1_hx_0_hz_0/H/2.npy\")\n",
    "x1 = groundstate.copy()\n",
    "x0 = groundstate.reshape([8] * 4)\n",
    "x0 = x0.transpose([0, 2, 1, 3]).reshape(-1)\n",
    "x0 = jnp.array(x0)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "SH0 = rms.sum_ham(H0, [[0,2]], 4, 8)\n",
    "SH1 = rms.sum_ham(H1, [[0,1]], 4, 8)\n",
    "SH2 = rms.sum_ham(H2, [[0,3]], 4, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bonds = [[0,0,2], [1,0,1], [2,0,3], [0,1,3], [1,1,0], [2,1,2], [0,2,0], [1,2,3], \n",
    "            [2,2,1], [0,3,1], [1,3,2], [2,3,0]]\n",
    "bonds = [[], [], []]\n",
    "for bond in _bonds:\n",
    "    bonds[bond[0]].append(bond[1:])\n",
    "\n",
    "_H = rms.sum_ham(rms.stoquastic(H0), bonds[0], 4, 8)\n",
    "_H += rms.sum_ham(rms.stoquastic(H1), bonds[1], 4, 8)\n",
    "_H += rms.sum_ham(rms.stoquastic(H2), bonds[2], 4, 8)\n",
    "\n",
    "u2 = np.kron(u, u)\n",
    "_HU = rms.sum_ham(rms.stoquastic(u2@H0@u2.T), bonds[0], 4, 8)\n",
    "_HU += rms.sum_ham(rms.stoquastic(u2@H1@u2.T), bonds[1], 4, 8)\n",
    "_HU += rms.sum_ham(rms.stoquastic(u2@H2@u2.T), bonds[2], 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.052132213843223\n",
      "-6.22515992356388\n"
     ]
    }
   ],
   "source": [
    "U = np.kron(u,u)\n",
    "U = np.kron(U,U)\n",
    "\n",
    "SH = SH0 + SH1 + SH2\n",
    "\n",
    "x = jnp.abs(U @ groundstate)\n",
    "print(x @ _HU @ x)\n",
    "x = jnp.abs(groundstate)\n",
    "print(x @ rms.stoquastic(H) @ x)\n",
    "# print(groundstate @ rms.stoquastic(H) @ groundstate)\n",
    "\n",
    "# jnp.linalg.eigvalsh(rms.stoquastic(U @ H @ U.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.052130856520556"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.763032714130139 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.579816545884742e-14"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(_H - rms.stoquastic(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-8.19503796, -7.8031308 , -7.8031308 , ...,  5.        ,\n",
       "        6.        ,  6.        ], dtype=float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.eigvalsh(rms.stoquastic(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-8.19503796, -7.8031308 , -7.8031308 , ...,  5.        ,\n",
       "        6.        ,  6.        ], dtype=float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.eigvalsh(_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-5.44487522, -5.3283924 , -5.29823654, ...,  6.        ,\n",
       "        6.        ,  6.        ], dtype=float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.eigvalsh(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.52065724, dtype=float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = rms.loss.init_loss(jnp.array(H1), 8, np.float64, \"qes\", X=jnp.array(x1))\n",
    "qesLoss = rms.loss.qes_multi\n",
    "\n",
    "qesLoss([state], jnp.array(u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "u = np.load(\"/home/user/project/python/rmsKit/array/KH/3site/sel/Jx_1_Jy_1_Jz_1_hx_0_hz_0/M_1/u/0.npy\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def random_unitary_matrix(size, device):\n",
    "    random_matrix = np.random.randn(size, size)\n",
    "    q, _ = np.linalg.qr(random_matrix)\n",
    "    return torch.tensor(u, dtype=torch.float64, device=device)\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, H_size, unitary_size):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        # Calculate the number of unitary matrices required to match the size of 'H'\n",
    "        n_us = round(math.log2(H_size) / math.log2(unitary_size))\n",
    "        self.n_us = n_us\n",
    "\n",
    "        # Initialize the given number of random unitary matrices\n",
    "        self.us = nn.ParameterList([nn.Parameter(random_unitary_matrix(unitary_size, device), requires_grad=True) for _ in range(n_us)])\n",
    "\n",
    "    def forward(self):\n",
    "        # Calculate U as the Kronecker product of all the unitary matrices in 'us'\n",
    "        U = self.us[0]\n",
    "        U = torch.kron(U, self.us[1])\n",
    "        U = torch.kron(U, self.us[2])\n",
    "        U = torch.kron(U, self.us[3])\n",
    "        # for i in range(4):\n",
    "        #     U = torch.kron(U, self.us[i+1])\n",
    "        # for u in self.us[1:]:\n",
    "        #     U = torch.kron(U, u)\n",
    "        return U\n",
    "\n",
    "def custom_loss(U, H):\n",
    "    # Calculate U @ H @ U.T\n",
    "    A = torch.matmul(U, torch.matmul(H, U.T))\n",
    "\n",
    "    # Calculate the absolute value of the result\n",
    "    a = torch.max(torch.diag(A)) * torch.eye(A.shape[0], device=device)\n",
    "    result_abs = -torch.abs(A - a) + a\n",
    "\n",
    "    # Calculate the minimum eigenvalue\n",
    "    E = torch.linalg.eigvalsh(result_abs)\n",
    "    z = torch.exp(-E * 1).sum()\n",
    "    return torch.log(z)\n",
    "\n",
    "p = dict(\n",
    "    Jx=1,\n",
    "    Jy=1,\n",
    "    Jz=1,\n",
    "    hx=0,\n",
    "    hz=0,\n",
    ")\n",
    "H = KH.system([2, 2], \"3site\", p)\n",
    "\n",
    "# Create an instance of the CustomModel class\n",
    "model = CustomModel(H.shape[0], 8).to(device)\n",
    "compiled_model = torch.compile(model, dynamic = False, fullgraph=True)\n",
    "# Calculate the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "635093cb382d24e7bb09df67eef84e97b3e0429c00b0294b3c9882ac411b8a1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
