{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from rms_torch import functions as torch_func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the matrix\n",
    "n = 4  # Example size\n",
    "\n",
    "H = torch.randn(n*n, n*n, dtype=torch.float32, requires_grad=False).to(device)\n",
    "H = H + H.T\n",
    "\n",
    "# Initialize a complex matrix\n",
    "ur = torch.randn(n, n, dtype=torch.float32).to(device)\n",
    "ui = torch.randn(n, n, dtype=torch.float32).to(device)\n",
    "ur.requires_grad_(True)\n",
    "ui.requires_grad_(True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam([ur, ui], lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6714,  0.6498, -0.5819, -0.1031,  0.6498,  0.0102, -0.3789, -1.0525,\n",
      "         -0.5819, -0.3789,  0.4495,  0.3732, -0.1031, -1.0525,  0.3732, -1.4512],\n",
      "        [ 0.5893,  0.3301,  0.1562, -1.0576,  0.8706,  1.3997,  0.9986, -0.5873,\n",
      "         -0.6002, -0.6079, -0.3878,  0.7867,  0.3718,  1.6125,  1.2809,  0.8343],\n",
      "        [-0.0463,  0.4983, -0.6735, -0.1756,  0.6645,  0.2427,  0.5911,  0.0642,\n",
      "         -0.1712, -0.3605,  0.2135,  0.0824,  1.0993, -0.4455,  2.0174,  0.3874],\n",
      "        [ 1.2420,  0.0872, -1.0920, -1.6372,  1.3947, -1.4615, -1.6558, -1.4931,\n",
      "         -1.1338,  0.3849,  1.1249,  1.3918,  0.1058, -2.3938, -0.7544,  0.3924],\n",
      "        [ 0.5893,  0.8706, -0.6002,  0.3718,  0.3301,  1.3997, -0.6079,  1.6125,\n",
      "          0.1562,  0.9986, -0.3878,  1.2809, -1.0576, -0.5873,  0.7867,  0.8343],\n",
      "        [ 0.3715, -0.2343, -0.2741, -1.1399, -0.2343, -1.7233, -1.4026, -1.2817,\n",
      "         -0.2741, -1.4026, -1.1244, -0.8437, -1.1399, -1.2817, -0.8437,  1.3582],\n",
      "        [-0.3848,  0.5536, -1.1942, -0.2676, -1.2610,  0.6633, -2.5011, -0.4949,\n",
      "         -0.9823,  0.4441, -1.8592, -0.3614, -0.4272, -0.6159,  0.1844,  0.1115],\n",
      "        [ 0.9966,  0.8266, -0.6678, -1.4813,  0.2745,  2.7416,  0.5085, -0.9648,\n",
      "          0.0251,  2.1376,  0.5662, -0.5063, -2.0921,  0.9528,  2.1424,  2.5143],\n",
      "        [-0.0463,  0.6645, -0.1712,  1.0993,  0.4983,  0.2427, -0.3605, -0.4455,\n",
      "         -0.6735,  0.5911,  0.2135,  2.0174, -0.1756,  0.0642,  0.0824,  0.3874],\n",
      "        [-0.3848, -1.2610, -0.9823, -0.4272,  0.5536,  0.6633,  0.4441, -0.6159,\n",
      "         -1.1942, -2.5011, -1.8592,  0.1844, -0.2676, -0.4949, -0.3614,  0.1115],\n",
      "        [-0.8100,  0.2403, -1.3785, -0.2562,  0.2403,  0.2770, -0.0185, -0.0396,\n",
      "         -1.3785, -0.0185, -1.8215, -0.2941, -0.2562, -0.0396, -0.2941, -0.0426],\n",
      "        [-0.3065,  1.7662,  0.7619,  0.0080,  0.9963, -0.5340, -1.0424, -1.1796,\n",
      "         -1.6328,  3.0182,  2.2985,  1.4585, -0.3976,  0.5620,  0.5121,  0.3934],\n",
      "        [ 1.2420,  1.3947, -1.1338,  0.1058,  0.0872, -1.4615,  0.3849, -2.3938,\n",
      "         -1.0920, -1.6558,  1.1249, -0.7544, -1.6372, -1.4931,  1.3918,  0.3924],\n",
      "        [ 0.9966,  0.2745,  0.0251, -2.0921,  0.8266,  2.7416,  2.1376,  0.9528,\n",
      "         -0.6678,  0.5085,  0.5662,  2.1424, -1.4813, -0.9648, -0.5063,  2.5143],\n",
      "        [-0.3065,  0.9963, -1.6328, -0.3976,  1.7662, -0.5340,  3.0182,  0.5620,\n",
      "          0.7619, -1.0424,  2.2985,  0.5121,  0.0080, -1.1796,  1.4585,  0.3934],\n",
      "        [ 2.2375,  0.6425, -1.8336, -3.0570,  0.6425, -3.8512, -1.6381,  0.0160,\n",
      "         -1.8336, -1.6381,  1.1964,  2.7514, -3.0570,  0.0160,  2.7514,  3.9787]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>) tensor([[ 0.3503, -0.3880, -0.0870, -1.1732, -0.3880, -0.7563,  0.4497, -0.5268,\n",
      "         -0.0870,  0.4497, -0.0836,  0.8355, -1.1732, -0.5268,  0.8355,  1.1175],\n",
      "        [ 0.6602,  1.4414,  1.0772, -0.0391, -0.1557,  0.4740,  0.4313,  0.8796,\n",
      "         -0.3355, -0.9749, -0.7515, -0.2394, -1.3250, -1.6395, -1.1067,  1.4187],\n",
      "        [ 0.8093, -0.0216,  1.1091,  0.1834,  0.4633, -0.4354,  1.1542,  0.2455,\n",
      "         -0.6061,  0.1422, -0.9853, -0.1792, -0.6169, -0.6350, -0.0460,  0.0765],\n",
      "        [ 0.8743, -1.7709, -1.2734, -0.7466, -0.5991, -1.0019,  0.2624,  1.0023,\n",
      "         -0.3272,  1.3227,  0.6584,  0.1333, -2.3597,  1.3685,  2.4973,  2.7708],\n",
      "        [ 0.6602, -0.1557, -0.3355, -1.3250,  1.4414,  0.4740, -0.9749, -1.6395,\n",
      "          1.0772,  0.4313, -0.7515, -1.1067, -0.0391,  0.8796, -0.2394,  1.4187],\n",
      "        [ 0.9650,  1.7119,  1.2420, -0.4795,  1.7119,  2.3165,  1.5968, -1.6209,\n",
      "          1.2420,  1.5968,  1.0878, -1.2657, -0.4795, -1.6209, -1.2657, -0.5854],\n",
      "        [ 0.8655,  0.1822,  0.9342,  0.1280,  0.9564,  0.7130,  0.4043, -0.0285,\n",
      "          0.6264,  0.5627,  0.1474, -0.0504, -1.0491,  0.3263, -1.8039, -0.3368],\n",
      "        [ 1.4686, -1.8998, -1.8429, -1.4922,  2.9529, -2.1139, -3.2357, -3.3784,\n",
      "          2.1829, -1.3873, -2.3436, -2.5363, -0.3579,  2.2872,  0.9516, -0.0404],\n",
      "        [ 0.8093,  0.4633, -0.6061, -0.6169, -0.0216, -0.4354,  0.1422, -0.6350,\n",
      "          1.1091,  1.1542, -0.9853, -0.0460,  0.1834,  0.2455, -0.1792,  0.0765],\n",
      "        [ 0.8655,  0.9564,  0.6264, -1.0491,  0.1822,  0.7130,  0.5627,  0.3263,\n",
      "          0.9342,  0.4043,  0.1474, -1.8039,  0.1280, -0.0285, -0.0504, -0.3368],\n",
      "        [ 0.3109,  0.4767, -0.1691, -0.0906,  0.4767, -0.1765,  0.8544,  0.1625,\n",
      "         -0.1691,  0.8544, -1.2748, -0.3205, -0.0906,  0.1625, -0.3205, -0.0737],\n",
      "        [ 1.5965, -0.6942, -1.6258, -1.9260,  0.0891, -1.0385, -0.3661,  0.1139,\n",
      "          2.0264,  0.3459, -1.7256, -2.7164,  0.3181,  0.1936, -0.2325, -0.4573],\n",
      "        [ 0.8743, -0.5991, -0.3272, -2.3597, -1.7709, -1.0019,  1.3227,  1.3685,\n",
      "         -1.2734,  0.2624,  0.6584,  2.4973, -0.7466,  1.0023,  0.1333,  2.7708],\n",
      "        [ 1.4686,  2.9529,  2.1829, -0.3579, -1.8998, -2.1139, -1.3873,  2.2872,\n",
      "         -1.8429, -3.2357, -2.3436,  0.9516, -1.4922, -3.3784, -2.5363, -0.0404],\n",
      "        [ 1.5965,  0.0891,  2.0264,  0.3181, -0.6942, -1.0385,  0.3459,  0.1936,\n",
      "         -1.6258, -0.3661, -1.7256, -0.2325, -1.9260,  0.1139, -2.7164, -0.4573],\n",
      "        [ 2.0671, -3.4974, -2.8208, -1.9181, -3.4974,  1.5492,  3.5694,  4.2128,\n",
      "         -2.8208,  3.5694,  3.5179,  2.8839, -1.9181,  4.2128,  2.8839,  1.5654]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[-1.0651e+01, -3.4864e+01, -2.0328e+01, -2.6525e+01,  2.3202e+00,\n",
      "         -2.7442e+01, -2.9084e+01,  3.4298e+00, -2.3048e+00, -2.7948e+01,\n",
      "         -2.5817e+01,  3.7733e+00, -2.8007e+01, -5.0899e+01, -8.1585e-02,\n",
      "         -3.7575e+01],\n",
      "        [-3.4864e+01, -8.8183e+00, -4.0656e+00, -7.8766e+01,  1.1716e+01,\n",
      "          4.1196e+01,  6.9181e+00, -6.4115e+01,  1.3434e+01, -1.2215e+01,\n",
      "         -2.2690e+01,  1.6103e+01, -1.0029e+02, -4.8586e+01, -1.2734e+01,\n",
      "         -1.4587e+02],\n",
      "        [-2.0328e+01, -4.0656e+00, -1.1797e+01, -3.4861e+01,  1.2980e+01,\n",
      "         -7.2247e+00, -5.2440e+00,  3.3016e+00, -1.0705e+00, -1.8866e+01,\n",
      "         -1.6041e+01, -5.2696e+00, -4.6503e+01, -2.9148e+01, -2.1602e+01,\n",
      "         -6.4749e+01],\n",
      "        [-2.6525e+01, -7.8766e+01, -3.4861e+01, -1.1571e+02, -3.3333e+01,\n",
      "         -5.6451e+01, -8.1027e+01,  5.3189e+01, -1.1850e+01, -2.7616e+01,\n",
      "         -2.7633e+01, -9.9951e+00, -1.2119e+02, -1.7143e+02, -8.3672e+01,\n",
      "         -2.4265e+02],\n",
      "        [ 2.3202e+00,  1.1716e+01,  1.2980e+01, -3.3333e+01,  3.6227e-01,\n",
      "         -7.9553e+01, -5.9893e+01,  4.4340e+01,  1.3661e+01,  2.6936e+00,\n",
      "         -1.7844e+01,  2.9229e+01, -2.0200e+01, -2.0459e+01,  1.8676e+01,\n",
      "         -1.7588e+02],\n",
      "        [-2.7442e+01,  4.1196e+01, -7.2247e+00, -5.6451e+01, -7.9553e+01,\n",
      "          9.5991e+01,  4.3834e+01, -1.1065e+02, -4.7377e+01,  5.7626e+01,\n",
      "          1.9388e+01, -6.1414e+01, -1.3541e+01,  3.9077e+01, -4.6130e+01,\n",
      "         -8.8701e+01],\n",
      "        [-2.9084e+01,  6.9181e+00, -5.2440e+00, -8.1027e+01, -5.9893e+01,\n",
      "          4.3834e+01,  2.2844e+01, -4.1669e+01, -4.9031e+01, -2.7051e+00,\n",
      "          7.0983e+00, -9.0836e+01,  1.7412e+00, -3.0923e-01, -3.4027e+01,\n",
      "         -7.9223e+01],\n",
      "        [ 3.4298e+00, -6.4115e+01,  3.3016e+00,  5.3189e+01,  4.4340e+01,\n",
      "         -1.1065e+02, -4.1669e+01,  1.1995e+02, -8.7808e-01, -9.7855e-01,\n",
      "          8.3346e-01,  6.2104e+01,  4.8948e+00, -1.0103e+02, -2.2101e+01,\n",
      "         -1.3555e+02],\n",
      "        [-2.3048e+00,  1.3434e+01, -1.0705e+00, -1.1850e+01,  1.3661e+01,\n",
      "         -4.7377e+01, -4.9031e+01, -8.7808e-01,  5.2235e+01,  9.0653e+00,\n",
      "          2.7669e+00,  6.3118e+01, -2.3894e+01,  5.5136e+00,  1.5559e+01,\n",
      "         -3.3623e+01],\n",
      "        [-2.7948e+01, -1.2215e+01, -1.8866e+01, -2.7616e+01,  2.6936e+00,\n",
      "          5.7626e+01, -2.7051e+00, -9.7855e-01,  9.0653e+00,  2.1278e+01,\n",
      "         -1.0786e+01,  3.6116e+01, -3.2295e+01,  1.9095e+01, -2.2365e+01,\n",
      "         -6.2821e+01],\n",
      "        [-2.5817e+01, -2.2690e+01, -1.6041e+01, -2.7633e+01, -1.7844e+01,\n",
      "          1.9388e+01,  7.0983e+00,  8.3345e-01,  2.7669e+00, -1.0786e+01,\n",
      "          2.1705e+00, -4.7020e+00,  4.3280e+00, -4.3365e+01, -2.6863e+01,\n",
      "         -3.5234e+01],\n",
      "        [ 3.7734e+00,  1.6103e+01, -5.2696e+00, -9.9950e+00,  2.9229e+01,\n",
      "         -6.1414e+01, -9.0836e+01,  6.2104e+01,  6.3118e+01,  3.6116e+01,\n",
      "         -4.7020e+00,  1.4762e+02, -5.3174e+01, -2.1398e+01,  9.1500e+00,\n",
      "         -1.1072e+02],\n",
      "        [-2.8007e+01, -1.0029e+02, -4.6503e+01, -1.2119e+02, -2.0200e+01,\n",
      "         -1.3541e+01,  1.7412e+00,  4.8948e+00, -2.3894e+01, -3.2295e+01,\n",
      "          4.3280e+00, -5.3174e+01, -1.1067e+02, -9.0090e+01, -4.4450e+01,\n",
      "         -2.8890e+02],\n",
      "        [-5.0899e+01, -4.8586e+01, -2.9148e+01, -1.7143e+02, -2.0459e+01,\n",
      "          3.9077e+01, -3.0923e-01, -1.0103e+02,  5.5136e+00,  1.9095e+01,\n",
      "         -4.3365e+01, -2.1398e+01, -9.0090e+01, -1.0397e+02,  6.6980e+01,\n",
      "         -2.6397e+02],\n",
      "        [-8.1585e-02, -1.2734e+01, -2.1602e+01, -8.3672e+01,  1.8676e+01,\n",
      "         -4.6130e+01, -3.4027e+01, -2.2101e+01,  1.5559e+01, -2.2365e+01,\n",
      "         -2.6863e+01,  9.1500e+00, -4.4450e+01,  6.6980e+01,  7.5691e+00,\n",
      "         -2.4250e+02],\n",
      "        [-3.7575e+01, -1.4587e+02, -6.4749e+01, -2.4265e+02, -1.7588e+02,\n",
      "         -8.8701e+01, -7.9223e+01, -1.3555e+02, -3.3623e+01, -6.2821e+01,\n",
      "         -3.5234e+01, -1.1072e+02, -2.8890e+02, -2.6397e+02, -2.4250e+02,\n",
      "         -5.6626e+02]], device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 0.0000e+00, -1.4905e+01, -3.1257e+00, -3.5116e+01,  1.6010e+01,\n",
      "          3.4647e+00, -2.6999e+00,  2.3098e+01,  1.3038e+00, -6.9870e+00,\n",
      "          1.4418e+01,  2.9580e+00, -4.0135e+01, -4.6331e+01, -1.3318e+01,\n",
      "         -1.2065e+02],\n",
      "        [ 1.4905e+01,  9.5367e-07, -1.5539e+01, -1.8117e+01, -3.1997e+01,\n",
      "          3.3367e+01, -6.4337e+00, -3.1917e+01, -1.3806e+01,  2.0608e+01,\n",
      "          3.6602e-01, -2.4593e+01,  2.8804e+01, -4.5001e+01, -2.7651e+00,\n",
      "         -4.3196e+01],\n",
      "        [ 3.1257e+00,  1.5539e+01, -5.3644e-07, -3.2087e+01, -2.4418e+01,\n",
      "         -1.6527e+01, -4.7777e+01, -3.9563e+01, -1.2513e+00, -1.8593e+01,\n",
      "         -1.9046e+01,  1.0347e+00,  1.0842e+01,  2.7796e+01,  1.6965e+01,\n",
      "         -7.0305e+01],\n",
      "        [ 3.5116e+01,  1.8117e+01,  3.2087e+01, -6.1989e-06, -1.7288e+01,\n",
      "          4.5739e+01,  2.1435e+01, -8.4975e+01,  1.8148e+01,  3.6628e+01,\n",
      "          4.2602e+01, -1.2458e+01, -1.8769e+01, -6.1865e+01, -8.5205e+00,\n",
      "         -1.3335e+02],\n",
      "        [-1.6010e+01,  3.1997e+01,  2.4418e+01,  1.7288e+01,  0.0000e+00,\n",
      "          3.5459e+01,  3.9764e+01, -1.4968e+01, -4.3339e+01,  3.1804e+00,\n",
      "          8.9434e+00, -4.7091e+01,  1.5980e+01,  1.6929e+01,  4.5827e+00,\n",
      "          4.7219e+01],\n",
      "        [-3.4647e+00, -3.3367e+01,  1.6527e+01, -4.5739e+01, -3.5459e+01,\n",
      "         -1.9073e-06, -3.0527e+01, -1.0267e+02, -2.6221e+01, -4.5366e+01,\n",
      "         -2.6143e+01, -9.0112e+01,  3.4073e+01,  1.1790e+01,  3.2771e+01,\n",
      "          1.2842e+00],\n",
      "        [ 2.6999e+00,  6.4337e+00,  4.7777e+01, -2.1435e+01, -3.9764e+01,\n",
      "          3.0527e+01,  0.0000e+00, -1.0050e+02, -3.1425e+01, -1.8475e+01,\n",
      "         -1.9934e+01, -9.2867e+01, -6.2213e+00,  5.3356e+00,  4.1570e+01,\n",
      "         -2.7033e+01],\n",
      "        [-2.3098e+01,  3.1917e+01,  3.9563e+01,  8.4975e+01,  1.4968e+01,\n",
      "          1.0267e+02,  1.0050e+02,  3.8147e-06, -6.2958e+01, -6.4047e+00,\n",
      "          1.9888e+00, -9.8668e+01,  8.7381e+01, -6.0793e+01, -1.8113e+01,\n",
      "          3.8506e+02],\n",
      "        [-1.3038e+00,  1.3806e+01,  1.2513e+00, -1.8148e+01,  4.3339e+01,\n",
      "          2.6221e+01,  3.1425e+01,  6.2958e+01,  2.8610e-06,  5.6420e+00,\n",
      "          1.2950e+01,  3.3059e+01, -1.3045e+01, -9.6488e+00, -2.0029e+01,\n",
      "         -4.3625e+01],\n",
      "        [ 6.9870e+00, -2.0608e+01,  1.8593e+01, -3.6628e+01, -3.1804e+00,\n",
      "          4.5366e+01,  1.8475e+01,  6.4047e+00, -5.6420e+00, -2.8610e-06,\n",
      "          1.7694e+01, -2.1838e+01, -9.3297e+00, -2.7423e+01, -1.9030e+01,\n",
      "         -5.2802e+01],\n",
      "        [-1.4418e+01, -3.6602e-01,  1.9046e+01, -4.2602e+01, -8.9434e+00,\n",
      "          2.6143e+01,  1.9934e+01, -1.9888e+00, -1.2950e+01, -1.7694e+01,\n",
      "         -1.6689e-06, -2.0199e+01, -1.2825e+01, -1.5448e+01,  4.7668e-01,\n",
      "         -3.1210e+01],\n",
      "        [-2.9580e+00,  2.4593e+01, -1.0347e+00,  1.2458e+01,  4.7091e+01,\n",
      "          9.0112e+01,  9.2867e+01,  9.8668e+01, -3.3059e+01,  2.1838e+01,\n",
      "          2.0199e+01,  1.1444e-05,  1.6003e+01, -2.7888e+01, -4.7792e+01,\n",
      "         -1.0900e+01],\n",
      "        [ 4.0135e+01, -2.8804e+01, -1.0842e+01,  1.8769e+01, -1.5980e+01,\n",
      "         -3.4073e+01,  6.2213e+00, -8.7381e+01,  1.3045e+01,  9.3297e+00,\n",
      "          1.2825e+01, -1.6003e+01,  0.0000e+00, -1.1535e+02, -8.3699e+01,\n",
      "         -8.7686e+01],\n",
      "        [ 4.6331e+01,  4.5001e+01, -2.7796e+01,  6.1865e+01, -1.6929e+01,\n",
      "         -1.1790e+01, -5.3356e+00,  6.0793e+01,  9.6488e+00,  2.7423e+01,\n",
      "          1.5448e+01,  2.7888e+01,  1.1535e+02,  5.7220e-06, -3.9183e+00,\n",
      "          4.5603e+01],\n",
      "        [ 1.3318e+01,  2.7651e+00, -1.6965e+01,  8.5205e+00, -4.5827e+00,\n",
      "         -3.2771e+01, -4.1570e+01,  1.8113e+01,  2.0029e+01,  1.9030e+01,\n",
      "         -4.7668e-01,  4.7792e+01,  8.3699e+01,  3.9183e+00,  4.7684e-06,\n",
      "         -7.9942e+01],\n",
      "        [ 1.2065e+02,  4.3196e+01,  7.0305e+01,  1.3335e+02, -4.7219e+01,\n",
      "         -1.2842e+00,  2.7033e+01, -3.8506e+02,  4.3625e+01,  5.2802e+01,\n",
      "          3.1210e+01,  1.0900e+01,  8.7686e+01, -4.5603e+01,  7.9942e+01,\n",
      "         -3.0518e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-16105.0781, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_func.nonstoq_complex(ur, ui, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.complex(torch.randn(4, 4), torch.randn(4, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = torch.matrix_exp(A - A.H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00+0.0000e+00j, -9.6858e-08-2.9802e-08j,\n",
       "         -4.4703e-08+3.1572e-07j, -1.7881e-07-9.6858e-08j],\n",
       "        [-9.6858e-08+2.9802e-08j,  1.0000e+00+0.0000e+00j,\n",
       "          1.4156e-07+2.9802e-08j,  7.4506e-08+1.6578e-07j],\n",
       "        [-4.4703e-08-3.1572e-07j,  1.4156e-07-2.9802e-08j,\n",
       "          1.0000e+00+0.0000e+00j, -8.9407e-08-4.4703e-08j],\n",
       "        [-1.7881e-07+9.6858e-08j,  7.4506e-08-1.6578e-07j,\n",
       "         -8.9407e-08+4.4703e-08j,  1.0000e+00+0.0000e+00j]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U @ U.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 ms ± 11.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the size of the matrices\n",
    "n = 100  # You can adjust this size based on your computational resources\n",
    "\n",
    "# Generate random real and imaginary parts for u1 and u2\n",
    "ur1 = torch.randn(n, n)\n",
    "ui1 = torch.randn(n, n)\n",
    "ur2 = torch.randn(n, n)\n",
    "ui2 = torch.randn(n, n)\n",
    "\n",
    "u1 = torch.complex(ur1, ui1)\n",
    "u2 = torch.complex(ur2, ui2)\n",
    "\n",
    "# Create ComplexMat instances\n",
    "%timeit torch_func.kron_complex(ur1, ui1, ur2, ui2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 ms ± 2.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.kron(u1, u2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by kron_complex: 33.3795 seconds\n",
      "Time taken by torch.kron: 8.0395 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define the size of the matrices for the test\n",
    "n = 100  # You can adjust this size based on your computational resources\n",
    "\n",
    "# Generate random real and imaginary parts for u1 and u2\n",
    "ur1 = torch.randn(n, n)\n",
    "ui1 = torch.randn(n, n)\n",
    "ur2 = torch.randn(n, n)\n",
    "ui2 = torch.randn(n, n)\n",
    "\n",
    "u1 = torch.complex(ur1, ui1)\n",
    "u2 = torch.complex(ur2, ui2)\n",
    "\n",
    "# Time the kron_complex function\n",
    "start_time_kron_complex = time.time()\n",
    "for _ in range(100):\n",
    "    torch_func.kron_complex(ur1, ui1, ur2, ui2)\n",
    "end_time_kron_complex = time.time()\n",
    "time_kron_complex = end_time_kron_complex - start_time_kron_complex\n",
    "\n",
    "# Time the torch.kron function\n",
    "start_time_kron = time.time()\n",
    "for _ in range(100):\n",
    "    torch.kron(u1, u2)\n",
    "end_time_kron = time.time()\n",
    "time_kron = end_time_kron - start_time_kron\n",
    "\n",
    "print(f\"Time taken by kron_complex: {time_kron_complex:.4f} seconds\")\n",
    "print(f\"Time taken by torch.kron: {time_kron:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by custom matmul: 0.0091 seconds\n",
      "Time taken by torch.matmul: 0.0029 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Define the size of the matrices\n",
    "n = 100  # Adjust based on computational resources\n",
    "\n",
    "# Generate random real and imaginary parts for u1 and u2\n",
    "ur1 = torch.randn(n, n, dtype=torch.float32)\n",
    "ui1 = torch.randn(n, n, dtype=torch.float32)\n",
    "ur2 = torch.randn(n, n, dtype=torch.float32)\n",
    "ui2 = torch.randn(n, n, dtype=torch.float32)\n",
    "\n",
    "u1 = torch.complex(ur1, ui1)\n",
    "u2 = torch.complex(ur2, ui2)\n",
    "\n",
    "# Time the custom matrix multiplication function (if exists)\n",
    "start_time_custom = time.time()\n",
    "for _ in range(100):\n",
    "    # Replace 'custom_matmul' with your custom function if it exists\n",
    "    # result_custom = torch.matmul(u1, u2)  # Example placeholder\n",
    "    result_custom = torch_func.matmal_complex(ur1, ui1, ur2, ui2)\n",
    "end_time_custom = time.time()\n",
    "time_custom = end_time_custom - start_time_custom\n",
    "\n",
    "# Time the torch.matmul function\n",
    "start_time_torch = time.time()\n",
    "for _ in range(100):\n",
    "    result_torch = torch.matmul(u1, u2)\n",
    "end_time_torch = time.time()\n",
    "time_torch = end_time_torch - start_time_torch\n",
    "\n",
    "print(f\"Time taken by custom matmul: {time_custom:.4f} seconds\")\n",
    "print(f\"Time taken by torch.matmul: {time_torch:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     matmul_result_custom \u001b[38;5;241m=\u001b[39m torch_func\u001b[38;5;241m.\u001b[39mmatmal_complex(UR1, UI1, UR1\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;241m-\u001b[39mUI1\u001b[38;5;241m.\u001b[39mT)  \u001b[38;5;66;03m# Custom matrix multiplication\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     trace_result_custom \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtrace(matmul_result_custom[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(matmul_result_custom[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mtrace_result_custom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m end_time_custom \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m time_custom \u001b[38;5;241m=\u001b[39m end_time_custom \u001b[38;5;241m-\u001b[39m start_time_custom\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/autograd/__init__.py:260\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    251\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    252\u001b[0m     (inputs,)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 260\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/autograd/__init__.py:133\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_floating_point:\n\u001b[1;32m    137\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "# Define the size of the matrices\n",
    "n = 10  # Smaller size for demonstration; adjust based on computational resources\n",
    "\n",
    "# Generate random real and imaginary parts for u1 and u2\n",
    "ur1 = torch.randn(n, n, dtype=torch.float32, requires_grad=True)\n",
    "ui1 = torch.randn(n, n, dtype=torch.float32, requires_grad=True)\n",
    "ur2 = torch.randn(n, n, dtype=torch.float32, requires_grad=True)\n",
    "ui2 = torch.randn(n, n, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "u1 = torch.complex(ur1, ui1)\n",
    "u2 = torch.complex(ur2, ui2)\n",
    "\n",
    "# Time the custom operations\n",
    "start_time_custom = time.time()\n",
    "for _ in range(100):\n",
    "    # Assuming custom_kron and custom_matmul are your custom functions\n",
    "    kron_result_custom = torch_func.kron_complex(ur1, ui1, ur2, ui2)  # Custom Kronecker product\n",
    "    UR1, UI1 = kron_result_custom\n",
    "    matmul_result_custom = torch_func.matmal_complex(UR1, UI1, UR1.T, -UI1.T)  # Custom matrix multiplication\n",
    "    trace_result_custom = torch.trace(matmul_result_custom[1]) + torch.abs(matmul_result_custom[0]).sum()\n",
    "    trace_result_custom.backward()\n",
    "end_time_custom = time.time()\n",
    "time_custom = end_time_custom - start_time_custom\n",
    "\n",
    "# Time the built-in operations\n",
    "start_time_builtin = time.time()\n",
    "for _ in range(100):\n",
    "    kron_result_builtin = torch.kron(u1, u2)  # Built-in Kronecker product\n",
    "    matmul_result_builtin = torch.matmul(kron_result_builtin, torch.conj(kron_result_builtin).t())  # Built-in matrix multiplication\n",
    "    trace_result_builtin = torch.trace(matmul_result_builtin) + torch.abs(matmul_result_builtin).sum()\n",
    "    trace_result_builtin.backward()\n",
    "end_time_builtin = time.time()\n",
    "time_builtin = end_time_builtin - start_time_builtin\n",
    "\n",
    "print(f\"Time taken by custom operations: {time_custom:.4f} seconds\")\n",
    "print(f\"Time taken by built-in operations: {time_builtin:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
