{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba84ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import os\n",
    "from utils import optm\n",
    "from utils.functions import *\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "\n",
    "I = np.identity(2)\n",
    "Sz = np.zeros([2,2])\n",
    "Sz[0,0] = 1/2\n",
    "Sz[1,1] = -1/2\n",
    "Sx = np.zeros([2,2])\n",
    "Sx[1,0] = 1/2\n",
    "Sx[0,1] = 1/2\n",
    "Sy = np.zeros([2,2], dtype=np.complex64)\n",
    "Sy[1,0] = 1j/2\n",
    "Sy[0,1] = -1j/2\n",
    "\n",
    "\n",
    "Sz = sparse.csr_matrix(Sz)\n",
    "Sx = sparse.csr_matrix(Sx)\n",
    "Sy = sparse.csr_matrix(Sy)\n",
    "I = sparse.csr_matrix(I)\n",
    "\n",
    "h1 = -(sparse.kron(sparse.kron(I,Sz,format='csr'), sparse.kron(Sz,I,format='csr'),format='csr') \n",
    "       - sparse.kron(sparse.kron(I,Sx,format='csr'), sparse.kron(Sx,I,format='csr'),format='csr')\n",
    "       - sparse.kron(sparse.kron(I,Sy,format='csr'), sparse.kron(Sy,I,format='csr'),format='csr') \n",
    "     ).real\n",
    "\n",
    "\n",
    "h2 = -(sparse.kron(sparse.kron(Sz,I,format='csr'), sparse.kron(Sz,I,format='csr'),format='csr') \n",
    "       - sparse.kron(sparse.kron(Sx,I,format='csr'), sparse.kron(Sx,I,format='csr'),format='csr')\n",
    "       - sparse.kron(sparse.kron(Sy,I,format='csr'), sparse.kron(Sy,I,format='csr'),format='csr') \n",
    "     ).real\n",
    "\n",
    "\n",
    "h3 = -(sparse.kron(sparse.kron(Sz,Sz,format='csr'), sparse.kron(I,I,format='csr'),format='csr') \n",
    "       + sparse.kron(sparse.kron(Sx,Sx,format='csr'), sparse.kron(I,I,format='csr'),format='csr')\n",
    "       + sparse.kron(sparse.kron(Sy,Sy,format='csr'), sparse.kron(I,I,format='csr'),format='csr') \n",
    "     ).real\n",
    "\n",
    "h4 = -(sparse.kron(sparse.kron(I,I,format='csr'), sparse.kron(Sz,Sz,format='csr'),format='csr') \n",
    "       + sparse.kron(sparse.kron(I,I,format='csr'), sparse.kron(Sx,Sx,format='csr'),format='csr')\n",
    "       + sparse.kron(sparse.kron(I,I,format='csr'), sparse.kron(Sy,Sy,format='csr'),format='csr') \n",
    "     ).real\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h1_ = -(sparse.kron(sparse.kron(Sz,I,format='csr'), sparse.kron(I,Sz,format='csr'),format='csr') \n",
    "       - sparse.kron(sparse.kron(Sx,I,format='csr'), sparse.kron(I,Sx,format='csr'),format='csr')\n",
    "       - sparse.kron(sparse.kron(Sy,I,format='csr'), sparse.kron(I,Sy,format='csr'),format='csr') \n",
    "     ).real\n",
    "\n",
    "h2_ = -(sparse.kron(sparse.kron(I,Sz,format='csr'), sparse.kron(I,Sz,format='csr'),format='csr') \n",
    "       - sparse.kron(sparse.kron(I,Sx,format='csr'), sparse.kron(I,Sx,format='csr'),format='csr')\n",
    "       - sparse.kron(sparse.kron(I,Sy,format='csr'), sparse.kron(I,Sy,format='csr'),format='csr') \n",
    "     ).real\n",
    "\n",
    "\n",
    "\n",
    "h = h1 + h2\n",
    "\n",
    "h_ = h1_ + h2_\n",
    "\n",
    "on_site = h3/4 + h4/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2212d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "J1 = 0.3\n",
    "X1 = torch.tensor((J1 * h + on_site).toarray())\n",
    "X1_prime = X1 - torch.eye(X1.shape[0])*(torch.diag(X1).min())\n",
    "\n",
    "X2 = torch.tensor((J1 * h_ + on_site).toarray())\n",
    "X2_prime = X2 - torch.eye(X2.shape[0])*(torch.diag(X2).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae285f36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target loss : 0.650\n",
      "\n",
      "---------- iteration start ----------\n",
      "iteration :    0   loss : 0.924\n",
      "iteration : 1000   loss : 0.823\n",
      "iteration : 2000   loss : 0.768\n",
      "iteration : 3000   loss : 0.753\n",
      "iteration : 4000   loss : 0.750\n",
      "iteration : 5000   loss : 0.750\n",
      "iteration : 6000   loss : 0.750\n",
      "iteration : 7000   loss : 0.750\n",
      "iteration : 8000   loss : 0.750\n",
      "iteration : 9000   loss : 0.750\n",
      "\n",
      " -------------- results --------------\n",
      "target loss      : 0.650\n",
      "loss before optm : 0.750\n",
      "loss after optm  : 0.750\n"
     ]
    }
   ],
   "source": [
    "reload(optm)\n",
    "model, gl = optm.optim_matrix_symm([X2_prime], 10000, optm_method = torch.optim.SGD, seed = 1, lr = 0.0001, momentum = 0.9,weight_decay = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "tired-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.det(torch.abs(model.matrix)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "genetic-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.abs(model.matrix)\n",
    "input2 = torch.abs(model.matrix)\n",
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(input1, input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "informal-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3482-0.2558j,  0.0600+0.2633j,  0.0794+0.2549j, -0.0255+0.3171j,\n",
       "          0.0600+0.2633j,  0.0793-0.1490j,  0.0667-0.1529j,  0.1417-0.1395j,\n",
       "          0.0794+0.2549j,  0.0667-0.1529j,  0.0540-0.1558j,  0.1289-0.1483j,\n",
       "         -0.0255+0.3171j,  0.1417-0.1395j,  0.1289-0.1483j,  0.2085-0.1067j],\n",
       "        [ 0.0600+0.2633j, -0.3947-0.1984j,  0.0671+0.2867j,  0.0452+0.2743j,\n",
       "          0.0793-0.1490j,  0.1055+0.2552j,  0.0855-0.1630j,  0.0907-0.1482j,\n",
       "          0.0667-0.1529j,  0.1235+0.2434j,  0.0717-0.1672j,  0.0781-0.1530j,\n",
       "          0.1417-0.1395j,  0.0284+0.3240j,  0.1536-0.1530j,  0.1543-0.1344j],\n",
       "        [ 0.0794+0.2549j,  0.0671+0.2867j, -0.4420-0.1041j,  0.0923+0.2437j,\n",
       "          0.0667-0.1529j,  0.0855-0.1630j,  0.1664+0.2299j,  0.0560-0.1530j,\n",
       "          0.0540-0.1558j,  0.0717-0.1672j,  0.1816+0.2138j,  0.0435-0.1550j,\n",
       "          0.1289-0.1483j,  0.1536-0.1530j,  0.1058+0.3171j,  0.1170-0.1521j],\n",
       "        [-0.0255+0.3171j,  0.0452+0.2743j,  0.0923+0.2437j, -0.3470-0.2555j,\n",
       "          0.1417-0.1395j,  0.0907-0.1482j,  0.0560-0.1530j,  0.0596+0.2627j,\n",
       "          0.1289-0.1483j,  0.0781-0.1530j,  0.0435-0.1550j,  0.0789+0.2543j,\n",
       "          0.2085-0.1067j,  0.1543-0.1344j,  0.1170-0.1521j, -0.0258+0.3162j],\n",
       "        [ 0.0600+0.2633j,  0.0793-0.1490j,  0.0667-0.1529j,  0.1417-0.1395j,\n",
       "         -0.3947-0.1984j,  0.1055+0.2552j,  0.1235+0.2434j,  0.0284+0.3240j,\n",
       "          0.0671+0.2867j,  0.0855-0.1630j,  0.0717-0.1672j,  0.1536-0.1530j,\n",
       "          0.0452+0.2743j,  0.0907-0.1482j,  0.0781-0.1530j,  0.1543-0.1344j],\n",
       "        [ 0.0793-0.1490j,  0.1055+0.2552j,  0.0855-0.1630j,  0.0907-0.1482j,\n",
       "          0.1055+0.2552j, -0.4318-0.1326j,  0.1167+0.2776j,  0.0924+0.2688j,\n",
       "          0.0855-0.1630j,  0.1167+0.2776j,  0.0922-0.1783j,  0.0980-0.1621j,\n",
       "          0.0907-0.1482j,  0.0924+0.2688j,  0.0980-0.1621j,  0.1025-0.1465j],\n",
       "        [ 0.0667-0.1529j,  0.0855-0.1630j,  0.1664+0.2299j,  0.0560-0.1530j,\n",
       "          0.1235+0.2434j,  0.1167+0.2776j, -0.4633-0.0294j,  0.1347+0.2299j,\n",
       "          0.0717-0.1672j,  0.0922-0.1783j,  0.1829+0.2496j,  0.0601-0.1671j,\n",
       "          0.0781-0.1530j,  0.0980-0.1621j,  0.1566+0.2466j,  0.0671-0.1536j],\n",
       "        [ 0.1417-0.1395j,  0.0907-0.1482j,  0.0560-0.1530j,  0.0596+0.2627j,\n",
       "          0.0284+0.3240j,  0.0924+0.2688j,  0.1347+0.2299j, -0.3935-0.1983j,\n",
       "          0.1536-0.1530j,  0.0980-0.1621j,  0.0601-0.1671j,  0.0667+0.2860j,\n",
       "          0.1543-0.1344j,  0.1025-0.1465j,  0.0671-0.1536j,  0.0448+0.2736j],\n",
       "        [ 0.0794+0.2549j,  0.0667-0.1529j,  0.0540-0.1558j,  0.1289-0.1483j,\n",
       "          0.0671+0.2867j,  0.0855-0.1630j,  0.0717-0.1672j,  0.1536-0.1530j,\n",
       "         -0.4420-0.1041j,  0.1664+0.2299j,  0.1816+0.2138j,  0.1058+0.3171j,\n",
       "          0.0923+0.2437j,  0.0560-0.1530j,  0.0435-0.1550j,  0.1170-0.1521j],\n",
       "        [ 0.0667-0.1529j,  0.1235+0.2434j,  0.0717-0.1672j,  0.0781-0.1530j,\n",
       "          0.0855-0.1630j,  0.1167+0.2776j,  0.0922-0.1783j,  0.0980-0.1621j,\n",
       "          0.1664+0.2299j, -0.4633-0.0294j,  0.1829+0.2496j,  0.1566+0.2466j,\n",
       "          0.0560-0.1530j,  0.1347+0.2299j,  0.0601-0.1671j,  0.0671-0.1536j],\n",
       "        [ 0.0540-0.1558j,  0.0717-0.1672j,  0.1816+0.2138j,  0.0435-0.1550j,\n",
       "          0.0717-0.1672j,  0.0922-0.1783j,  0.1829+0.2496j,  0.0601-0.1671j,\n",
       "          0.1816+0.2138j,  0.1829+0.2496j, -0.4702+0.0812j,  0.1895+0.1977j,\n",
       "          0.0435-0.1550j,  0.0601-0.1671j,  0.1895+0.1977j,  0.0333-0.1536j],\n",
       "        [ 0.1289-0.1483j,  0.0781-0.1530j,  0.0435-0.1550j,  0.0789+0.2543j,\n",
       "          0.1536-0.1530j,  0.0980-0.1621j,  0.0601-0.1671j,  0.0667+0.2860j,\n",
       "          0.1058+0.3171j,  0.1566+0.2466j,  0.1895+0.1977j, -0.4407-0.1043j,\n",
       "          0.1170-0.1521j,  0.0671-0.1536j,  0.0333-0.1536j,  0.0918+0.2432j],\n",
       "        [-0.0255+0.3171j,  0.1417-0.1395j,  0.1289-0.1483j,  0.2085-0.1067j,\n",
       "          0.0452+0.2743j,  0.0907-0.1482j,  0.0781-0.1530j,  0.1543-0.1344j,\n",
       "          0.0923+0.2437j,  0.0560-0.1530j,  0.0435-0.1550j,  0.1170-0.1521j,\n",
       "         -0.3470-0.2555j,  0.0596+0.2627j,  0.0789+0.2543j, -0.0258+0.3162j],\n",
       "        [ 0.1417-0.1395j,  0.0284+0.3240j,  0.1536-0.1530j,  0.1543-0.1344j,\n",
       "          0.0907-0.1482j,  0.0924+0.2688j,  0.0980-0.1621j,  0.1025-0.1465j,\n",
       "          0.0560-0.1530j,  0.1347+0.2299j,  0.0601-0.1671j,  0.0671-0.1536j,\n",
       "          0.0596+0.2627j, -0.3935-0.1983j,  0.0667+0.2860j,  0.0448+0.2736j],\n",
       "        [ 0.1289-0.1483j,  0.1536-0.1530j,  0.1058+0.3171j,  0.1170-0.1521j,\n",
       "          0.0781-0.1530j,  0.0980-0.1621j,  0.1566+0.2466j,  0.0671-0.1536j,\n",
       "          0.0435-0.1550j,  0.0601-0.1671j,  0.1895+0.1977j,  0.0333-0.1536j,\n",
       "          0.0789+0.2543j,  0.0667+0.2860j, -0.4407-0.1043j,  0.0918+0.2432j],\n",
       "        [ 0.2085-0.1067j,  0.1543-0.1344j,  0.1170-0.1521j, -0.0258+0.3162j,\n",
       "          0.1543-0.1344j,  0.1025-0.1465j,  0.0671-0.1536j,  0.0448+0.2736j,\n",
       "          0.1170-0.1521j,  0.0671-0.1536j,  0.0333-0.1536j,  0.0918+0.2432j,\n",
       "         -0.0258+0.3162j,  0.0448+0.2736j,  0.0918+0.2432j, -0.3458-0.2552j]],\n",
       "       dtype=torch.complex128, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "differential-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_prime = X2_prime.type(torch.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "disturbed-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = model.matrix\n",
    "model._params = torch.nn.Parameter(model._params + 0.001 * model._params.grad)\n",
    "# T - model.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "subtle-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 7.8543e-01,  7.8533e-01, -1.4895e-07,  1.0178e-04,  7.8543e-01,\n",
       "         7.8533e-01], requires_grad=True)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "harmful-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "E, V = torch.linalg.eigh(torch.abs(model.matrix @ X2_prime @ model.matrix.T))\n",
    "E1, V1 = torch.linalg.eigh(torch.abs(X2_prime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "israeli-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0149e-01, -2.4152e-05, -5.0257e-05, -8.1539e-08, -2.6583e-05,\n",
       "        -4.5218e-01, -4.5229e-01, -2.6654e-05, -2.6586e-05, -4.5223e-01,\n",
       "        -4.5234e-01, -2.6645e-05, -8.0982e-08, -5.0152e-05, -2.4125e-05,\n",
       "        -3.0157e-01], dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:,-1].conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "moral-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  7.4138e-17,  1.9331e-16, -3.0151e-01, -4.1387e-17,\n",
       "        -4.5227e-01, -4.5227e-01,  0.0000e+00, -4.1387e-17, -4.5227e-01,\n",
       "        -4.5227e-01, -4.0580e-32, -3.0151e-01, -1.2174e-32, -6.0870e-32,\n",
       "         0.0000e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V1[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "expressed-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_prime = torch.rand(16,16, dtype = torch.float64)*2-1\n",
    "X1_prime = X1_prime + X1_prime.T\n",
    "X1_prime = X1_prime + torch.eye(16)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "wound-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = optm.unitary_solver([4,4],syms=True, seed = 101)\n",
    "Y = torch.abs((model2.matrix @ X1_prime @ model2.matrix.T))\n",
    "E, V = np.linalg.eigh(np.array(Y.detach()))\n",
    "loss = torch.sum(torch.tensor(V[:,-1][:, None] @ V[:,-1][None, :]) * Y)\n",
    "loss.backward()\n",
    "# Y[1,1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "israeli-horizon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6779, -0.5087, -0.2851,  0.9110,  0.3692,  1.4537])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2._params.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
