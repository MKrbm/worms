{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescription-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "further-andrew",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keisukemurota/miniconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:16: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "L = 6\n",
    "\n",
    "Sz = np.zeros([2,2])\n",
    "Sz[0,0] = 1/2\n",
    "Sz[1,1] = -1/2\n",
    "Sx = np.zeros([2,2])\n",
    "Sx[1,0] = 1/2\n",
    "Sx[0,1] = 1/2\n",
    "Sy = np.zeros([2,2], dtype=np.complex64)\n",
    "Sy[1,0] = 1j/2\n",
    "Sy[0,1] = -1j/2\n",
    "\n",
    "\n",
    "SzSz = np.kron(Sz,Sz).astype(np.float64)\n",
    "SxSx = np.kron(Sx,Sx).astype(np.float64)\n",
    "SySy = np.kron(Sy,Sy).astype(np.float64)\n",
    "\n",
    "lh = SzSz + SxSx + SySy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-newark",
   "metadata": {},
   "source": [
    "### exact diagonalization with original matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "joint-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.25000000e+00 -2.25000000e+00 -1.75000000e+00 -1.75000000e+00\n",
      " -1.75000000e+00 -1.56872930e+00 -1.56872930e+00 -1.56872930e+00\n",
      " -1.56872930e+00 -1.56872930e+00 -1.56872930e+00 -1.25000000e+00\n",
      " -1.25000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      " -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -2.50000000e-01\n",
      " -2.50000000e-01 -2.50000000e-01 -2.50000000e-01 -2.50000000e-01\n",
      " -2.50000000e-01 -5.30516917e-16 -4.91759089e-16 -3.05973681e-16\n",
      " -9.62409177e-17 -7.01392900e-17  1.16958990e-16  2.24511772e-16\n",
      "  3.25195482e-16  4.63662579e-16  5.11587843e-16  2.50000000e-01\n",
      "  2.50000000e-01  2.50000000e-01  2.50000000e-01  2.50000000e-01\n",
      "  2.50000000e-01  3.18729304e-01  3.18729304e-01  3.18729304e-01\n",
      "  3.18729304e-01  3.18729304e-01  3.18729304e-01  1.00000000e+00\n",
      "  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  1.00000000e+00  2.25000000e+00  2.25000000e+00  2.25000000e+00\n",
      "  2.25000000e+00  2.25000000e+00  2.25000000e+00  2.25000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keisukemurota/miniconda3/envs/research/lib/python3.7/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "import functions as f\n",
    "from importlib import reload\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "import scipy\n",
    "reload(f)\n",
    "\n",
    "H = sparse.csr_matrix((2**L, 2**L), dtype=np.float64)\n",
    "for i in range(L):\n",
    "    \n",
    "    H += f.l2nl(lh, L, [i,(i+1)%L], sps = 2)\n",
    "    H += f.l2nl(lh/2, L, [i,(i+2)%L], sps = 2)   \n",
    "\n",
    "E, V = np.linalg.eigh(H.toarray())\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-partner",
   "metadata": {},
   "source": [
    "### rewritten with projection operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "freelance-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "LH = sparse.csr_matrix((2**3,2**3), dtype = np.float64)\n",
    "i = 0\n",
    "LH += f.l2nl(lh/2, 3, [i,(i+1)%L], sps = 2)\n",
    "LH += f.l2nl(lh/2, 3, [(i+1)%L,(i+2)%L], sps = 2)\n",
    "LH += f.l2nl(lh/2, 3, [i,(i+2)%L], sps = 2) \n",
    "LH = LH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "photographic-peeing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function scipy.sparse.construct.kron(A, B, format=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse.kron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "measured-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "LH_ = sparse.csr_matrix((2**3,2**3), dtype = np.float64)\n",
    "i = 0\n",
    "LH_ += f.l2nl(lh/2, 3, [0, 1], sps = 2)\n",
    "LH_ += f.l2nl(lh/2, 3, [0, 2], sps = 2)\n",
    "LH_ += f.l2nl(lh/2, 3, [1, 2], sps = 2)\n",
    "\n",
    "\n",
    "\n",
    "LH = sparse.csr_matrix((2**6,2**6), dtype = np.float64)\n",
    "LH += f.l2nl(LH_/2, 6, [0, 1, 2], sps = 2)\n",
    "LH += f.l2nl(LH_, 6, [1, 2, 3], sps = 2)\n",
    "LH += f.l2nl(LH_, 6, [2, 3, 4], sps = 2)\n",
    "LH += f.l2nl(LH_/2, 6, [3, 4, 5], sps = 2)\n",
    "\n",
    "H = sparse.csr_matrix((2**6,2**6), dtype = np.float64)\n",
    "H += f.l2nl(LH, 2, [0, 1], sps = 8)\n",
    "H += f.l2nl(LH, 2, [1, 0], sps = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "supported-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = -LH.toarray()\n",
    "X = -H.toarray()\n",
    "X -= np.eye(X.shape[0]) * np.min(np.diag(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee548e4",
   "metadata": {},
   "source": [
    "### dual annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6bbf436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbackF(x, f, context):\n",
    "    print(\"target value : {:.5f} in the context {}\".format(f,context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "bibliographic-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\n",
      "target value : 8.23302 in the context 0\n",
      "target value : 8.20846 in the context 0\n",
      "target value : 5.27296 in the context 1\n",
      "target value : 5.01482 in the context 1\n",
      "target value : 4.95501 in the context 1\n",
      "target value : 4.94975 in the context 1\n",
      "target value : 4.94604 in the context 1\n",
      "target value : 4.94409 in the context 1\n",
      "target value : 4.94408 in the context 1\n",
      "target value : 4.94352 in the context 1\n",
      "     fun: 4.943524177271737\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 1459443\n",
      "    nhev: 0\n",
      "     nit: 10000\n",
      "    njev: 31015\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.75 , 0.729, 6.007, 5.32 , 0.197, 3.201, 0.831, 5.672, 6.28 ,\n",
      "       0.881, 0.174, 1.327, 0.   , 5.26 , 5.943, 5.071, 4.333, 5.71 ,\n",
      "       4.543, 6.016, 0.509, 6.283, 1.608, 1.083, 6.283, 4.471, 0.   ,\n",
      "       4.858])\n"
     ]
    }
   ],
   "source": [
    "from utils import optm\n",
    "reload(optm)\n",
    "# X = np.stack([X1_prime, X2_prime])\n",
    "func = optm.unitary_optm(X)\n",
    "import scipy.optimize as optimize\n",
    "bounds = [[0, 2*np.pi] for _ in range(28)]\n",
    "ret = optimize.dual_annealing(func, bounds = bounds, restart_temp_ratio = 1e-5, visit = 2.7, initial_temp = 3*10**4, maxiter = 10000, callback = callbackF)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3637b",
   "metadata": {},
   "source": [
    "### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "catholic-demand",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keisukemurota/Documents/todo/worms/python/nsp/utils/optm.py:440: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model._params = torch.nn.Parameter(torch.tensor(init_params))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target loss : 4.500\n",
      "\n",
      "---------- iteration start ----------\n",
      "iteration :    0   loss : 5.138\n",
      "iteration : 1000   loss : 5.139\n",
      "iteration : 2000   loss : 5.139\n",
      "iteration : 3000   loss : 5.139\n",
      "iteration : 4000   loss : 5.138\n",
      "iteration : 5000   loss : 5.139\n",
      "iteration : 6000   loss : 5.139\n",
      "iteration : 7000   loss : 5.139\n",
      "iteration : 8000   loss : 5.139\n",
      "iteration : 9000   loss : 5.139\n",
      "\n",
      " -------------- results --------------\n",
      "target loss      : 4.5000000000\n",
      "loss before optm : 5.6236516671\n",
      "loss after optm  : 5.1384372930\n"
     ]
    }
   ],
   "source": [
    "reload(optm)\n",
    "import torch.optim\n",
    "model, gl = optm.optim_matrix_symm([torch.tensor(X)], 10000, optm_method = torch.optim.SGD, seed = 10, lr = 0.001, init_params=model._params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "705a00a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.745e-16,  0.000e+00,  0.000e+00,  1.242e-17,  2.742e-17,\n",
       "        3.264e-17,  3.195e-16,  1.250e+00,  1.250e+00,  1.250e+00,\n",
       "        1.250e+00,  1.250e+00,  1.250e+00,  1.250e+00,  1.250e+00,\n",
       "        1.250e+00,  1.250e+00,  1.931e+00,  1.931e+00,  1.931e+00,\n",
       "        1.931e+00,  1.931e+00,  1.931e+00,  2.000e+00,  2.000e+00,\n",
       "        2.000e+00,  2.000e+00,  2.000e+00,  2.000e+00,  2.250e+00,\n",
       "        2.250e+00,  2.250e+00,  2.250e+00,  2.250e+00,  2.250e+00,\n",
       "        2.250e+00,  2.250e+00,  2.250e+00,  2.250e+00,  2.500e+00,\n",
       "        2.500e+00,  2.500e+00,  2.500e+00,  2.500e+00,  2.500e+00,\n",
       "        3.250e+00,  3.250e+00,  3.250e+00,  3.250e+00,  3.250e+00,\n",
       "        3.250e+00,  3.500e+00,  3.500e+00,  3.819e+00,  3.819e+00,\n",
       "        3.819e+00,  3.819e+00,  3.819e+00,  3.819e+00,  4.000e+00,\n",
       "        4.000e+00,  4.000e+00,  4.500e+00,  4.500e+00])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvalsh(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "automotive-raleigh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target loss : 2.250\n",
      "\n",
      "---------- iteration start ----------\n",
      "iteration :    0   loss : 20.031\n",
      "iteration : 1000   loss : 19.706\n",
      "iteration : 2000   loss : 19.703\n",
      "iteration : 3000   loss : 19.699\n",
      "iteration : 4000   loss : 19.704\n",
      "iteration : 5000   loss : 19.699\n",
      "iteration : 6000   loss : 19.701\n",
      "iteration : 7000   loss : 19.707\n",
      "iteration : 8000   loss : 19.705\n",
      "iteration : 9000   loss : 19.702\n",
      "\n",
      " -------------- results --------------\n",
      "target loss      : 2.2500000000\n",
      "loss before optm : 2.8182674076\n",
      "loss after optm  : 2.6929198104\n"
     ]
    }
   ],
   "source": [
    "reload(optm)\n",
    "import torch.optim\n",
    "model, gl = optm.optim_matrix_symm([torch.tensor(X)], 10000, optm_method = torch.optim.SGD, loss_func=optm.loss_1 , seed = 10, lr = 0.00001, init_params=model._params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c496a3d",
   "metadata": {},
   "source": [
    "### another cost function\n",
    "\n",
    "minimize $\\langle \\psi ^ + \\vert H^+ \\vert \\psi ^ + \\rangle$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b2d7b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keisukemurota/miniconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_prime = torch.tensor(X)\n",
    "X_prime = X_prime[None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "78ac00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(optm)\n",
    "solver = optm.unitary_solver2(X, [8,8], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c95b6f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration :    0   loss : 17.725\n",
      "iteration : 1000   loss : 11.772\n",
      "iteration : 2000   loss : 11.426\n",
      "iteration : 3000   loss : 11.365\n",
      "iteration : 4000   loss : 11.361\n",
      "iteration : 5000   loss : 11.359\n",
      "iteration : 6000   loss : 11.357\n",
      "iteration : 7000   loss : 11.357\n",
      "iteration : 8000   loss : 11.357\n",
      "iteration : 9000   loss : 11.358\n"
     ]
    }
   ],
   "source": [
    "for t in range(10**4):\n",
    "    optimizer = torch.optim.SGD(solver.parameters(), lr = 0.001)\n",
    "    M, V = solver()\n",
    "    loss_ = optm.loss_2(M,V)\n",
    "    optimizer.zero_grad()\n",
    "    loss_.backward()\n",
    "    if (t % 1000) == 0:\n",
    "        print(\"iteration : {:4d}   loss : {:.3f}\".format(t,loss_.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44771de",
   "metadata": {},
   "source": [
    "## test several optimization scheme\n",
    "\n",
    "$\\lambda_i$ is the eigenvalues of $(UHU^T)^+$\n",
    "$$\n",
    "E = \\max(\\lambda_i) \\\\\n",
    "w_{k+1} = w_k - \\alpha \\cdot \\gamma \\cdot \\text{sign}(\\partial E / \\partial w_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f408bfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.optm_method' from '/Users/keisukemurota/Documents/todo/worms/python/nsp/utils/optm_method.py'>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import optm_method as optmm\n",
    "reload(optm)\n",
    "reload(optmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e2ce44fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999539493585035"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10**5\n",
    "10**(np.log10(0.01)/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b1425777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target loss : 4.500\n",
      "loss before optm : 5.6236516671\n",
      "\n",
      "---------- iteration start ----------\n",
      "iteration :        0   loss : 8.868\tgamma = 0.0001\n",
      "iteration :     1000   loss : 8.278\tgamma = 0.0001\n",
      "iteration :     2000   loss : 7.840\tgamma = 0.0001\n",
      "iteration :     3000   loss : 7.414\tgamma = 0.0001\n",
      "iteration :     4000   loss : 7.099\tgamma = 0.0001\n",
      "iteration :     5000   loss : 6.848\tgamma = 0.0001\n",
      "iteration :     6000   loss : 6.494\tgamma = 0.0001\n",
      "iteration :     7000   loss : 5.841\tgamma = 0.0001\n",
      "iteration :     8000   loss : 5.349\tgamma = 0.0001\n",
      "iteration :     9000   loss : 5.249\tgamma = 0.0001\n",
      "iteration :    10000   loss : 5.230\tgamma = 0.0001\n",
      "iteration :    11000   loss : 5.224\tgamma = 0.0001\n",
      "iteration :    12000   loss : 5.123\tgamma = 0.0001\n",
      "iteration :    13000   loss : 4.894\tgamma = 0.0001\n",
      "iteration :    14000   loss : 4.778\tgamma = 0.0001\n",
      "iteration :    15000   loss : 4.765\tgamma = 0.0001\n",
      "iteration :    16000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    17000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    18000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    19000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    20000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    21000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    22000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    23000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    24000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    25000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    26000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    27000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    28000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    29000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    30000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    31000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    32000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    33000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    34000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    35000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    36000   loss : 4.761\tgamma = 0.0001\n",
      "iteration :    37000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    38000   loss : 4.762\tgamma = 0.0001\n",
      "iteration :    39000   loss : 4.761\tgamma = 0.0001\n",
      "\n",
      " -------------- results --------------\n",
      "target loss      : 4.5000000000\n",
      "loss before optm : 5.6236516671\n",
      "loss after optm  : 4.7617002238\n"
     ]
    }
   ],
   "source": [
    "reload(optm)\n",
    "import torch.optim\n",
    "model, gl = optm.optim_matrix_symm(\n",
    "        [torch.tensor(X)],\n",
    "        40000, \n",
    "        optm_method = optm.scheme1, \n",
    "        seed = 10,\n",
    "        gamma = 0.0001,\n",
    "        r = 1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ae225",
   "metadata": {},
   "source": [
    "## gridsearch revisit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d2383be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.optm_method' from '/Users/keisukemurota/Documents/todo/worms/python/nsp/utils/optm_method.py'>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import optm\n",
    "from utils import optm_method as optmm\n",
    "reload(optm)\n",
    "reload(optmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "669d0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_index = 4\n",
    "ranges = (slice(-10, 10), ) * n_index\n",
    "index = np.random.choice(28, n_index, replace=True)\n",
    "grid = optm.unitary_optm(X, 28, index=index, init_param = np.array(model._params.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3dacd2d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/m5qzz0hj12z06hxsn5km2c400000gn/T/ipykernel_6135/3474955355.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresbrute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_index\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     print(resbrute[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mbrute\u001b[0;34m(func, ranges, args, Ns, full_output, finish, disp, workers)\u001b[0m\n\u001b[1;32m   3260\u001b[0m     \u001b[0;31m# iterate over input arrays, possibly in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mMapWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3262\u001b[0;31m         \u001b[0mJout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3264\u001b[0m             \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   3332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3333\u001b[0m         \u001b[0;31m# flatten needed for one dimensional case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3334\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/todo/worms/python/nsp/utils/optm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, param)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0monesite_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monesite_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monesite_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_eig_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "for _ in range(100):\n",
    "    resbrute = scipy.optimize.brute(grid, ranges = ranges, full_output=True)\n",
    "    index = np.random.choice(28, n_index , replace=True)\n",
    "#     print(resbrute[0])\n",
    "    print(\"target {:.4f}\".format(resbrute[1]))\n",
    "#     print(grid.params)\n",
    "    grid = optm.unitary_optm(X, 28, index=index, init_param = grid.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "547dd9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 21,  1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8efe26a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.761640719693298"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0ecd8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.linspace(-100,100, 1000)\n",
    "y = []\n",
    "grid = optm.unitary_optm(X, 28, index=index, init_param = np.array(model._params.data))\n",
    "for t in T:\n",
    "    y.append(grid([t*np.pi+250]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bf76c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f845bbaa390>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(T,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1942945b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([248630.97], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.params[grid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d9f4328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.34404299e+00, 5.78362881e-04, 3.21762196e+00])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resbrute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6f005370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvalsh(grid.generators[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
